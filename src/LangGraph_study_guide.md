# LangGraph 학습 가이드

## 퀴즈❓

### Q. TypedDict가 일반 Python 딕셔너리에 비해 제공하는 두 가지 주요 이점은 무엇인가요? 
TypedDict는 일반 Python 딕셔너리에 비해 타입 안전성과 가독성 향상이라는 두 가지 주요 이점을 제공합니다. 타입 안전성은 런타임 오류를 줄여주고, 명시적인 타입 정의는 코드 이해와 디버깅을 용이하게 합니다.

### Q. LangGraph에서 상태(State)는 어떤 역할을 하나요? 비유를 들어 설명해 주세요. 
LangGraph에서 상태는 애플리케이션의 현재 정보나 컨텍스트를 담는 공유 데이터 구조입니다. 이는 마치 회의실의 화이트보드와 같아서, 모든 참가자(노드)가 접근하고 수정할 수 있는 애플리케이션의 기억 장치 역할을 합니다.

### Q. LangGraph에서 노드(Node)와 도구(Tool)의 주요 차이점은 무엇인가요? 
노드는 그래프 구조의 일부로, 특정 작업을 수행하는 개별 함수 또는 작업입니다. 반면, 도구는 노드 내에서 특정 작업을 수행하기 위해 활용되는 전문화된 함수나 유틸리티로, 노드의 기능을 향상시킵니다.

### Q. 조건부 엣지(Conditional Edge)는 LangGraph 워크플로우에서 어떤 기능을 제공하나요? 비유를 들어 설명해 주세요. 
조건부 엣지는 현재 상태에 적용된 특정 조건이나 논리를 기반으로 다음에 실행될 노드를 결정하는 특수 연결입니다. 이는 마치 신호등과 같아서, 신호등의 색깔(조건)에 따라 다음에 어느 길로 갈지(다음 노드)를 결정합니다.

### Q. React 에이전트(Reasoning and Acting Agent)의 핵심 개념인 "Reasoning and Acting"은 무엇을 의미하나요? 
React 에이전트에서 "Reasoning and Acting"은 LLM이 특정 쿼리에 대해 어떤 도구를 사용할지, 그리고 더 이상 도구 호출이 필요 없을 때 언제 작업을 종료할지 스스로 판단하는 과정을 의미합니다. 즉, 에이전트가 추론하여 행동을 결정합니다.

### Q. RAG(Retrieval Augmented Generation) 에이전트에서 "청킹(Chunking)" 과정과 "청크 오버랩(Chunk Overlap)"의 목적은 무엇인가요? 
RAG 에이전트에서 청킹 과정은 긴 문서를 더 작은 조각(청크)으로 나누는 것이고, 청크 오버랩은 연속적인 청크들이 일부 토큰을 공유하도록 하는 것입니다. 이들의 목적은 LLM이 검색에 더 적합한 작은 단위의 정보를 처리하고, 청크 경계에서 정보 손실을 최소화하여 컨텍스트를 유지하도록 돕는 것입니다.

## 핵심 용어집✏️
- LangGraph: 고급 대화형 AI 워크플로우를 구축하기 위한 강력한 Python 라이브러리. 그래프 기반 접근 방식을 사용하여 복잡한 대화 시스템을 설계, 구현 및 관리한다.
- 상태 (State): 전체 애플리케이션의 현재 정보 또는 컨텍스트를 담는 공유 데이터 구조. 노드가 실행되면서 접근하고 수정할 수 있는 애플리케이션의 메모리 역할을 한다.
- 노드 (Node): 그래프 내에서 특정 작업을 수행하는 개별 함수 또는 작업. 현재 상태를 입력으로 받아 처리하고 업데이트된 상태를 출력한다.
- 그래프 (Graph): 서로 다른 작업(노드)이 어떻게 연결되고 실행되는지를 매핑하는 전체적인 구조. 워크플로우를 시각적으로 나타내며 작업 간의 순서와 조건부 경로를 보여준다.
- 엣지 (Edge): 노드 간의 연결. 실행 흐름을 결정하며, 현재 노드가 작업을 완료한 후 다음에 어떤 노드가 실행되어야 하는지 알려준다.
- 조건부 엣지 (Conditional Edge): 현재 상태에 적용된 특정 조건이나 논리를 기반으로 다음에 실행될 노드를 결정하는 특수 연결.
- 시작점 (Start Point): LangGraph 워크플로우가 시작되는 가상 진입점. 자체적으로 작업을 수행하지는 않지만 그래프 실행을 위한 지정된 시작 위치 역할을 한다.
- 종료점 (End Point): LangGraph 워크플로우의 결론을 나타낸다. 애플리케이션이 이 노드에 도달하면 그래프의 실행이 완전히 중지되고 모든 의도된 프로세스가 완료되었음을 나타낸다.
- 도구 (Tool): 노드가 특정 작업을 수행하기 위해 활용할 수 있는 전문화된 함수 또는 유틸리티. 노드의 기능을 향상시킨다.
- 도구 노드 (Tool Node): 도구를 실행하는 것이 주된 작업인 특별한 종류의 노드. 도구의 출력을 다시 상태로 연결하여 다른 노드가 해당 정보를 사용할 수 있도록 한다.
- 상태 그래프 (State Graph): 그래프 구조를 구축하고 컴파일하는 주요 목적을 가진 요소. 노드, 엣지 및 전체 상태를 관리하여 워크플로우가 통일된 방식으로 작동하고 모든 데이터가 구성 요소 간에 올바르게 흐르도록 한다.
- 실행 가능한 구성 요소 (Runnable): AI 워크플로우 내에서 특정 작업을 수행하는 표준화된 실행 가능한 구성 요소. 모듈식 시스템을 생성하는 기본적인 빌딩 블록 역할을 한다.
- 메시지 종류
    - 인간 메시지 (Human Message): 사용자로부터의 입력을 나타내는 메시지 유형.
    - AI 메시지 (AI Message): AI 모델에 의해 생성된 응답을 나타내는 메시지 유형.
    - 시스템 메시지 (System Message): 모델에 지침이나 컨텍스트를 제공하는 데 사용되는 메시지 유형.
    - 도구 메시지 (Tool Message): 도구 사용에 특화된 메시지 유형.
    - 함수 메시지 (Function Message): 함수 호출의 결과를 나타내는 메시지 유형.
- TypedDict: Python에서 딕셔너리의 키와 값에 대한 타입 힌트를 제공하여 데이터 구조의 일관성을 보장하고 런타임 오류를 줄이는 데 사용되는 타입 어노테이션.
- Union: 변수가 여러 데이터 타입 중 하나를 가질 수 있음을 나타내는 타입 어노테이션.
- Optional: 변수가 지정된 타입 또는 None 값을 가질 수 있음을 나타내는 타입 어노테이션.
- Any: 변수가 어떤 데이터 타입이든 될 수 있음을 나타내는 타입 어노테이션.
- lambda 함수: 작은 익명 함수를 한 줄로 간결하게 작성할 수 있게 해주는 Python 기능.
- Annotated: 변수나 매개변수에 대한 추가 메타데이터나 컨텍스트를 제공할 수 있게 하는 타입 어노테이션.
- Sequence: 순서가 있는 컬렉션(예: 리스트, 튜플)의 타입을 나타내며, LangGraph에서는 상태 업데이트 시 메시지 추가 등 순차적 데이터 처리를 자동화하는 데 사용될 수 있다.
- 리듀서 함수 (Reducer Function): 노드에서 오는 업데이트가 기존 상태와 어떻게 결합되는지 제어하는 규칙. 새로운 데이터를 현재 상태에 병합하는 방법을 정의한다. (예: add_messages 함수는 새로운 메시지를 기존 메시지 목록에 추가하는 방식으로 상태를 업데이트한다.)
- React 에이전트 (Reasoning and Acting Agent): LLM이 추론(Reasoning)을 통해 어떤 도구를 사용할지 결정하고(Acting), 더 이상 도구 호출이 필요 없을 때 작업을 종료하는 유형의 AI 에이전트.
- RAG (Retrieval Augmented Generation): 검색 증강 생성. 외부 지식 베이스에서 관련 정보를 검색한 다음 LLM이 이를 사용하여 더 정확하고 사실적인 답변을 생성하는 시스템.
- 임베딩 모델 (Embedding Model): 텍스트를 고차원 벡터(수치 표현)로 변환하는 모델. 텍스트의 의미를 수치적으로 표현하여 유사성 검색 등을 가능하게 한다.
- 청킹 (Chunking): 긴 문서를 더 작고 관리하기 쉬운 텍스트 조각(청크)으로 나누는 과정. RAG 시스템에서 관련 정보를 효율적으로 검색하기 위해 사용된다.
- 청크 오버랩 (Chunk Overlap): 연속적인 청크들이 일부 텍스트를 공유하도록 하는 설정. 청크 경계에서 컨텍스트 손실을 방지하고 검색 관련성을 높이는 데 도움이 된다.
- 벡터 데이터베이스 (Vector Database): 임베딩 모델로 생성된 벡터를 저장하고 효율적으로 검색하도록 최적화된 데이터베이스.
- 리트리버 (Retriever): 주어진 쿼리에 대해 벡터 데이터베이스에서 가장 관련성이 높은 문서 청크를 검색하는 구성 요소.
- 온도 (Temperature): LLM의 출력 다양성(무작위성)을 제어하는 파라미터. 0에 가까울수록 결정론적이고 예측 가능한 출력을 생성하며, 1에 가까울수록 더 창의적이고 다양한 출력을 생성한다.