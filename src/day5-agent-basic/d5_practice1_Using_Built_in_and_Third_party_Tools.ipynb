{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeBJRhjieuVs"
   },
   "source": [
    "# [실습 1] Built-in & Third-party Tool 사용하기\n",
    "\n",
    "학습 내용:\n",
    "1. 환경 설정: 필요한 라이브러리 설치 및 API 키 설정\n",
    "2. Third-party Tool: Tavily 웹 검색 도구 사용법\n",
    "3. Built-in Tool: LangChain에서 기본 제공하는 DuckDuckGo 검색 도구 사용법\n",
    "4. Toolkit: 여러 도구를 한번에 가져오는 Toolkit 활용법 (Wikipedia)\n",
    "5. Agent 생성: 정의된 도구들을 활용하여 스스로 추론하고 답을 찾는 Agent 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tUouDVbe-kg"
   },
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9IMoZXNfChB",
    "outputId": "15f19f8b-07d4-4912-aed1-30efe3d99a35"
   },
   "outputs": [],
   "source": [
    "# 먼저 필요한 라이브러리들을 설치합니다.\n",
    "# !pip install -qU langchain langchain_openai langchain-community langchain-tavily tavily-python duckduckgo-search wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjSHVb-3fClx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드, 환경 변수에서 API 키 읽기\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AFsSP8VTfCpQ"
   },
   "outputs": [],
   "source": [
    "# LangChain 관련 기본 import\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import Tool\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "\n",
    "# LLM 모델을 초기화합니다. 이번 실습에서는 'gpt-4o-mini'를 사용합니다.\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\", # e.g. \"openai/gpt-4o-mini\", \"openai/gpt-5\"\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wE6OBqWfPYg"
   },
   "source": [
    "# 2. Third-party Tool: Tavily 웹 검색\n",
    "- Tavily는 AI Agent를 위해 특별히 설계된 검색 엔진입니다.  \n",
    "- 일반 검색 엔진보다 더 정확하고 간결한 정보를 제공하여 Agent의 성능을 높여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mrzW_6YfsRf"
   },
   "source": [
    "**Tavily API Key 발급 방법**\n",
    "1. Tavily 공식 홈페이지 접속: 우측 상단의 \"Sign in\" 또는 \"Sign up\"을 클릭하여 회원가입을 진행합니다. Google 계정으로 쉽게 가입할 수 있습니다.\n",
    "공식 사이트 : https://auth.tavily.com/u/login/identifier?state=hKFo2SBETnBjX3pFNy1ubEpzQ0Jtemo5dnhLSm5DTjVsd2pGSKFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIGh5ZWVYbm5TLW5DS2pwbEF4aDJITGhvSElFMTRmQTg3o2NpZNkgUlJJQXZ2WE5GeHBmVFdJb3pYMW1YcUxueVVtWVNUclE\n",
    "\n",
    "2. API Key 확인: 회원가입 후 대시보드(Dashboard)로 이동하면 \"API Key\" 섹션이 있습니다. 여기에 표시된 API 키를 복사합니다.\n",
    "\n",
    "3. 무료 사용: Tavily는 \"Researcher\" 플랜으로 월 1,000건의 무료 API 호출을 제공하므로, 실습용으로는 충분합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U2arRCNUfgy0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드, 환경 변수에서 API 키 읽기\n",
    "load_dotenv()\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "p7fuIXm6fg4g"
   },
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# Tavily 검색 도구를 생성합니다.\n",
    "# max_results는 검색 결과의 최대 개수를 지정합니다.\n",
    "tavily_tool = TavilySearch(\n",
    "    max_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvtjUHGTfg89",
    "outputId": "d66d0bb7-e4b9-485f-fee6-2b5536b5f877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tavily 검색 테스트 ---\n",
      "{'query': 'LangChain이란 무엇인가요?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://cloud.google.com/use-cases/langchain?hl=ko', 'title': 'LangChain이란 무엇인가요? 예시 및 정의', 'content': 'LangChain은 대규모 언어 모델(LLM)로 애플리케이션을 더 쉽게 빌드할 수 있도록 지원하는 오픈소스 조정 프레임워크입니다. LLM을 다양한 데이터 소스에 연결하는 도구와', 'score': 0.9255605, 'raw_content': None}, {'url': 'https://www.ibm.com/kr-ko/think/topics/langchain', 'title': 'LangChain이란 무엇인가요?', 'content': 'LangChain은 거의 모든 LLM을 위한 일반 인터페이스 역할을 하며 LLM 애플리케이션을 구축하고 이를 외부 데이터 소스 및 소프트웨어 워크플로와 통합할 수 있는 중앙 집중식 개발 환경을 제공합니다. LangChain은 챗봇, 지능형 검색, 질문 답변, 요약 서비스뿐만 아니라 로봇 프로세스 자동화가 가능한 가상 에이전트와 같은 LLM 및 자연어 처리(NLP)에 이르기까지 대부분의 사용 사례를 지원할 수 있습니다. BigScience의 BLOOM, Meta AI의 LLaMa, Google의 Flan-T5와 같은 많은 오픈 소스 모델은 Hugging Face(ibm.com 외부 링크)를 통해 액세스할 수 있습니다. LangChain은 기본 제공 파운데이션 모델에만 국한되지 않으며, *CustomLLM* 클래스(ibm.com 외부 링크)를 통해 사용자 지정 LLM 래퍼를 사용할 수 있습니다. 마찬가지로 LangChain 통합 기능이 포함된 IBM watsonx API 및 Python SDK를 통해 *WatsonxLLM* 클래스(및 해당 모델의 특정 프로젝트 ID)를 사용하여 특정 요구에 맞게 이미 학습했거나 미세 조정된 모델을 기반으로 LangChain에 애플리케이션을 구축할 수 있습니다.', 'score': 0.91936076, 'raw_content': None}, {'url': 'https://www.samsungsds.com/kr/insights/what-is-langchain.html', 'title': '랭체인 LangChain 이란 무엇인가? | 인사이트리포트', 'content': '+ 클라우드 보안 서비스 클라우드 보안 서비스 + 클라우드 보안 솔루션 운영 서비스 쉽고 편리하게 ML/DL 모델 개발 및 학습 환경을 구축할 수 있는 AI 서비스 - 클라우드 보안 서비스 * 클라우드 보안 서비스 * 클라우드 보안 솔루션 운영 서비스 **LangChain(랭체인)은 대규모 언어 모델(LLM)을 활용한 애플리케이션 개발에 특화된 오픈소스 프레임워크입니다.** LangChain은 기존 언어 모델의 한계를 극복하고, AI 기술을 활용한 새로운 애플리케이션을 구축할 수 있는 중요한 도구로 자리 잡고 있습니다. LangChain은 다음과 같은 기능들을 통해 다양한 산업에서 혁신적인 애플리케이션을 구축할 수 있는 강력한 도구로 자리 잡고 있습니다. LangChain은 다양한 언어 모델과 쉽게 통합할 수 있으며, 이를 통해 복잡하고 다양한 애플리케이션을 구축할 수 있습니다. 또한, LangChain은 여러 언어 모델과의 통합이 가능하여, 다양한 사용 사례에 맞춘 애플리케이션을 쉽게 구축할 수 있습니다.', 'score': 0.91306627, 'raw_content': None}, {'url': 'https://yongeekd01.tistory.com/92', 'title': '(1) Langchain이란 무엇인가? 개념과 모듈 구성을 알아보자', 'content': '모든 언어 모델 애플리케이션의 핵심 요소는 바로 모델입니다.LangChain은 모든 언어 모델과 인터페이스할 수 있는 빌딩 블록을 제공합니다. 많은 LLM 애플리케이션에는 모델 훈련 세트의 일부가 아닌 사용자별 데이터가 필요합니다.LangChain은 데이터를 로드,변환,저장 및 쿼리할 수 있는 빌딩 블록을 제공합니다: 간단한 애플리케이션의 경우 LLM을 단독으로 사용할 수 있지만 더 복잡한 애플리케이션의 경우 서로 또는 다른 기능을 수행하는 컴포넌트와 함께 LLM을 연결해야 합니다. LangChain은 이러한 컴포넌트를\"chain\"으로 연결할 수 있는 인터페이스를 제공하고 컴포넌트에 대한 호출 시퀀스로 정의합니다. 대부분의 LLM 애플리케이션에는 대화형 인터페이스가 있습니다.메모리는 이전 대화에 소개된 정보를 참조할 수 있도록 지원합니다. LangChain은 LLM 애플리케이션의 다양한 단계에 연결할 수 있는 콜백 시스템을 제공합니다. 이는 로깅,모니터링,스트리밍 및 기타 작업에 유용하며 API 전체에서 사용할 수 있는 콜백 인수를 사용하여 이러한 이벤트를 받을 수 있습니다. IT 정보, AI 딥러닝, 개발 자료, 코딩 블로그', 'score': 0.90692574, 'raw_content': None}, {'url': 'https://databoom.tistory.com/entry/LangChain-%EB%9E%AD%EC%B2%B4%EC%9D%B8%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80', 'title': '[LangChain] 랭체인이란 무엇인가 - 인공지능 개발자 수다', 'content': '자연어처리/Langchain *   모델 통합: 다양한 언어 모델을 하나의 통합된 인터페이스를 통해 손쉽게 접근하고 사용할 수 있습니다. *   **Language Model Wrappers**: 다양한 언어 모델(GPT, BERT 등)을 통합하여 사용할 수 있도록 하는 래퍼(wrapper)들입니다. *   **Connectors**:외부 시스템과의 연동을 관리하는 구성 요소입니다.데이터베이스,API,파일 시스템 등 다양한 외부 자원과의 통신을 가능하게 하며,이를 통해 애플리케이션이 더 많은 정보를 활용하고 더 정확한 응답을 제공할 수 있도록 돕습니다. *   **Configuration and Deployment Tools**:LangChain 애플리케이션을 구성하고 배포하는 데 사용되는 도구들입니다.이를 통해 개발 환경 설정,테스트,배포 등이 용이해지며,클라우드 환경이나 서버에서의 실행을 관리할 수 있습니다. | [[langchain] LLM(Large Language Model) 사용하기](https://databoom.tistory.com/entry/langchain-LLMLarge-Language-Model-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)(7) | 2024.09.12 | | [[Langchain] 랭체인 무엇을 공부해야 하나?](https://databoom.tistory.com/entry/Langchain-%EB%9E%AD%EC%B2%B4%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%B5%EB%B6%80%ED%95%B4%EC%95%BC-%ED%95%98%EB%82%98)(0) | 2024.08.20 | *   [다음글**[Langchain] 랭체인 무엇을 공부해야 하나?**](https://databoom.tistory.com/entry/Langchain-%EB%9E%AD%EC%B2%B4%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%B5%EB%B6%80%ED%95%B4%EC%95%BC-%ED%95%98%EB%82%98) *   [**[langchain] LLM(Large Language Model) 사용하기**2024.09.12](https://databoom.tistory.com/entry/langchain-LLMLarge-Language-Model-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0? *   [**[Langchain] 랭체인 무엇을 공부해야 하나?**2024.08.20](https://databoom.tistory.com/entry/Langchain-%EB%9E%AD%EC%B2%B4%EC%9D%B8-%EB%AC%B4%EC%97%87%EC%9D%84-%EA%B3%B5%EB%B6%80%ED%95%B4%EC%95%BC-%ED%95%98%EB%82%98? *   Langchain', 'score': 0.8170061, 'raw_content': None}], 'response_time': 0.73, 'request_id': '447a536c-fcda-40ec-9b24-2ab49f5fe28e'}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Tavily 도구를 직접 호출하여 테스트해볼 수 있습니다.\n",
    "print(\"--- Tavily 검색 테스트 ---\")\n",
    "search_result = tavily_tool.invoke({\"query\": \"LangChain이란 무엇인가요?\"})\n",
    "print(search_result)\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fXAEeNZgraW"
   },
   "source": [
    "# 3. Built-in Tool: DuckDuckGo 웹 검색\n",
    "- LangChain은 다양한 내장 도구를 제공합니다. DuckDuckGo는 그 중 하나로,\n",
    "- 별도의 API 키 없이 사용할 수 있는 검색 도구입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZLElno7LhJUl"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# DuckDuckGo 검색 도구를 생성합니다.\n",
    "duckduckgo_tool = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "An_-ubVMhJXV",
    "outputId": "1e15f07f-bb70-4dd4-b151-80e2c93e1927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DuckDuckGo 검색 테스트 ---\n",
      "Jul 20, 2025 · LangChain 主体分为 6 个模块，分别是对（大语言）模型输入输出的管理、外部数据接入、链的概念、（上下文记忆）存储管理、智能代理以及回调系统，通过文档的组织结构，你可以清晰 … 这算得上是一个非常惊艳的功能。 主要优点是，你用自然语言提出问题，LangChain把这个问题丢给LLMs，LLMs返回SQL脚本，然后LangChain会自动执行查询语句得到结果后，再丢给LLMs生成一 … 目前我把应用开发框架分成三类，一类是类似 langchain、llamaindex、semantic-kernel 这种偏整体流程设计、搭建，需要开发大量代码的。 一类是类似dify、fastgpt 这种轻代码，依靠 UI 界面上的编排 … LangChain的技术架构思路 不过，由于LangChain诞生时间较早，在2022年末，GPT-3.5刚诞生之时，开发者对大模型的想象主要是希望用其搭建一个又一个工作流，而这也成为LangChain的核心技术 … Langchain的学习路径 1、从官方文档入手，掌握LangChain的基本概念和使用方法。 2、了解LangChain的6大主要模块。 3、通读官方给出的示例，对于各个模块有更加直观的认识。 4、找一 …\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# DuckDuckGo 도구를 직접 호출하여 테스트해봅니다.\n",
    "print(\"--- DuckDuckGo 검색 테스트 ---\")\n",
    "search_result_ddg = duckduckgo_tool.run(\"LangChain이란 무엇인가요?\")\n",
    "print(search_result_ddg)\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X--41RUhdeV"
   },
   "source": [
    "# 4. Toolkit: File Management Toolkit\n",
    "- Toolkit은 특정 작업과 관련된 여러 도구의 묶음입니다.\n",
    "https://python.langchain.com/v0.1/docs/integrations/toolkits/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S6vf4E1BhJZt"
   },
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "# 파일 관리 툴킷 초기화\n",
    "fm_toolkit = FileManagementToolkit(root_dir=\"./my_agent_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Oz7cAQZhlZx",
    "outputId": "9c28b660-f084-42ff-d6e5-3b62702bf4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- File Management Toolkit 도구 목록 (7개) ---\n",
      "도구 이름: copy_file, 설명: Create a copy of a file in a specified location\n",
      "도구 이름: file_delete, 설명: Delete a file\n",
      "도구 이름: file_search, 설명: Recursively search for files in a subdirectory that match the regex pattern\n",
      "도구 이름: move_file, 설명: Move or rename a file from one location to another\n",
      "도구 이름: read_file, 설명: Read file from disk\n",
      "도구 이름: write_file, 설명: Write file to disk\n",
      "도구 이름: list_directory, 설명: List files and directories in a specified folder\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Toolkit에서 제공하는 도구들을 가져옵니다.\n",
    "# get_tools() 메서드는 Toolkit에 포함된 모든 도구의 리스트를 반환합니다.\n",
    "fm_tools = fm_toolkit.get_tools()\n",
    "print(f\"--- File Management Toolkit 도구 목록 ({len(fm_tools)}개) ---\")\n",
    "for tool in fm_tools:\n",
    "    print(f\"도구 이름: {tool.name}, 설명: {tool.description}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpVwy4F2hsh9"
   },
   "source": [
    "# 5. Agent 생성 및 실행\n",
    "\n",
    "이제 위에서 정의한 도구들을 Agent에게 부여하여 실제 문제를 해결하게 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KJ280nD1h1q1"
   },
   "outputs": [],
   "source": [
    "# Agent가 사용할 도구 목록을 정의합니다.\n",
    "# 각 Tool 객체는 이름(name), 실행할 함수(func), 그리고 설명(description)으로 구성됩니다.\n",
    "# 이 'description'은 Agent가 어떤 상황에 이 도구를 사용해야 할지 판단하는 매우 중요한 기준이 됩니다.\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Tavily-Search\",\n",
    "        func=tavily_tool.invoke,\n",
    "        description=\"최신 정보나 시사, 인물, 사실 관계 확인 등 웹 검색이 필요할 때 사용합니다. 다른 도구로 해결할 수 없는 질문에 대한 최종적인 답변 수단으로 유용합니다.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"DuckDuckGo-Search\",\n",
    "        func=duckduckgo_tool.run,\n",
    "        description=\"Tavily 검색 결과가 만족스럽지 않거나, 다른 관점의 웹 검색이 필요할 때 사용합니다.\",\n",
    "    ),\n",
    "    # Wikipedia Toolkit의 도구들을 리스트에 추가합니다.\n",
    "    *fm_tools\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2BXRHLah1z-",
    "outputId": "1bcf9d15-bb3d-499a-8f5e-81d8715a0ade"
   },
   "outputs": [],
   "source": [
    "# Agent를 만들기 위한 프롬프트를 가져옵니다.\n",
    "# hub.pull은 LangChain Hub에서 미리 만들어진 프롬프트 객체를 다운로드하는 기능입니다.\n",
    "# \"hwchase17/openai-functions-agent\"는 OpenAI의 함수 호출 기능에 최적화된 표준 프롬프트입니다.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKpNIQ2ziGo1",
    "outputId": "4f2ec0c5-9df7-4206-9db3-a4bcd190eace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 내용을 확인해볼 수 있습니다.\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uavGBdtFiHtN"
   },
   "outputs": [],
   "source": [
    "# OpenAI Functions Agent를 생성합니다.\n",
    "# 이 Agent는 LLM의 함수 호출(Function Calling) 기능을 사용하여 어떤 도구를 언제 호출할지 결정합니다.\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_function_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7ff085b83be0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7ff085b83be0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7ff0846d95a0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7ff0840fa560>, root_client=<openai.OpenAI object at 0x7ff0846d92a0>, root_async_client=<openai.AsyncOpenAI object at 0x7ff0840fa4a0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'functions': [{'name': 'Tavily-Search', 'description': '최신 정보나 시사, 인물, 사실 관계 확인 등 웹 검색이 필요할 때 사용합니다. 다른 도구로 해결할 수 없는 질문에 대한 최종적인 답변 수단으로 유용합니다.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}, {'name': 'DuckDuckGo-Search', 'description': 'Tavily 검색 결과가 만족스럽지 않거나, 다른 관점의 웹 검색이 필요할 때 사용합니다.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}, {'name': 'copy_file', 'description': 'Create a copy of a file in a specified location', 'parameters': {'properties': {'source_path': {'description': 'Path of the file to copy', 'type': 'string'}, 'destination_path': {'description': 'Path to save the copied file', 'type': 'string'}}, 'required': ['source_path', 'destination_path'], 'type': 'object'}}, {'name': 'file_delete', 'description': 'Delete a file', 'parameters': {'properties': {'file_path': {'description': 'Path of the file to delete', 'type': 'string'}}, 'required': ['file_path'], 'type': 'object'}}, {'name': 'file_search', 'description': 'Recursively search for files in a subdirectory that match the regex pattern', 'parameters': {'properties': {'dir_path': {'default': '.', 'description': 'Subdirectory to search in.', 'type': 'string'}, 'pattern': {'description': 'Unix shell regex, where * matches everything.', 'type': 'string'}}, 'required': ['pattern'], 'type': 'object'}}, {'name': 'move_file', 'description': 'Move or rename a file from one location to another', 'parameters': {'properties': {'source_path': {'description': 'Path of the file to move', 'type': 'string'}, 'destination_path': {'description': 'New path for the moved file', 'type': 'string'}}, 'required': ['source_path', 'destination_path'], 'type': 'object'}}, {'name': 'read_file', 'description': 'Read file from disk', 'parameters': {'properties': {'file_path': {'description': 'name of file', 'type': 'string'}}, 'required': ['file_path'], 'type': 'object'}}, {'name': 'write_file', 'description': 'Write file to disk', 'parameters': {'properties': {'file_path': {'description': 'name of file', 'type': 'string'}, 'text': {'description': 'text to write to file', 'type': 'string'}, 'append': {'default': False, 'description': 'Whether to append to an existing file.', 'type': 'boolean'}}, 'required': ['file_path', 'text'], 'type': 'object'}}, {'name': 'list_directory', 'description': 'List files and directories in a specified folder', 'parameters': {'properties': {'dir_path': {'default': '.', 'description': 'Subdirectory to list.', 'type': 'string'}}, 'type': 'object'}}]}, config={}, config_factories=[])\n",
       "| OpenAIFunctionsAgentOutputParser()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InputType',\n",
       " 'OutputType',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_setattr_handlers__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__ror__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abatch_with_config',\n",
       " '_abc_impl',\n",
       " '_acall_with_config',\n",
       " '_atransform',\n",
       " '_atransform_stream_with_config',\n",
       " '_batch_with_config',\n",
       " '_calculate_keys',\n",
       " '_call_with_config',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_is_protocol',\n",
       " '_iter',\n",
       " '_setattr_handler',\n",
       " '_transform',\n",
       " '_transform_stream_with_config',\n",
       " 'abatch',\n",
       " 'abatch_as_completed',\n",
       " 'ainvoke',\n",
       " 'as_tool',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'batch_as_completed',\n",
       " 'bind',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'first',\n",
       " 'from_orm',\n",
       " 'get_config_jsonschema',\n",
       " 'get_graph',\n",
       " 'get_input_jsonschema',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_output_jsonschema',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'input_schema',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'last',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'map',\n",
       " 'middle',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'name',\n",
       " 'output_schema',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'steps',\n",
       " 'stream',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'transform',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'with_alisteners',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sANd1uPSiHxu"
   },
   "outputs": [],
   "source": [
    "# AgentExecutor는 Agent의 실행을 담당합니다.\n",
    "# Agent가 도구를 호출하고, 그 결과를 다시 Agent에게 전달하는 등의 순환적인 과정을 관리합니다.\n",
    "# verbose=True로 설정하면 Agent의 생각의 흐름(Chain of Thought)을 자세히 볼 수 있습니다.\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyON3zhSiHz0",
    "outputId": "b27e9685-3773-4d18-849f-c3275fd0b67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agent 실행 예시 1 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\"Attention Is All You Need\" 논문의 저자는 다음과 같습니다:\n",
      "\n",
      "1. Ashish Vaswani\n",
      "2. Noam Shazeer\n",
      "3. Niki Parmar\n",
      "4. Jakob Uszkoreit\n",
      "5. Llion Jones\n",
      "6. Aidan N. Gomez\n",
      "7. Lukasz Kaiser\n",
      "8. Stephan Gouws\n",
      "9. Yoshua Bengio\n",
      "10. Geoffrey Hinton\n",
      "\n",
      "이 논문은 Google Brain 팀의 연구원들이 주로 작성하였으며, 저자들은 Google의 다양한 부서에 소속되어 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "[최종 답변]: \"Attention Is All You Need\" 논문의 저자는 다음과 같습니다:\n",
      "\n",
      "1. Ashish Vaswani\n",
      "2. Noam Shazeer\n",
      "3. Niki Parmar\n",
      "4. Jakob Uszkoreit\n",
      "5. Llion Jones\n",
      "6. Aidan N. Gomez\n",
      "7. Lukasz Kaiser\n",
      "8. Stephan Gouws\n",
      "9. Yoshua Bengio\n",
      "10. Geoffrey Hinton\n",
      "\n",
      "이 논문은 Google Brain 팀의 연구원들이 주로 작성하였으며, 저자들은 Google의 다양한 부서에 소속되어 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이제 Agent에게 질문을 던져보겠습니다.\n",
    "# Agent는 질문을 이해하고, 가장 적절한 도구를 선택하여 실행하고, 최종 답변을 생성합니다.\n",
    "print(\"\\n--- Agent 실행 예시 1 ---\")\n",
    "question1 = \"Attention Is All You Need 논문의 저자는 누구인가요? 그들의 소속도 알려주세요.\"\n",
    "response1 = agent_executor.invoke({\"input\": question1})\n",
    "print(\"\\n[최종 답변]:\", response1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjOoIULQiR-0",
    "outputId": "2d82b074-bb3d-444c-d2ad-cd12224b91b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agent 실행 예시 2 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Tavily-Search` with `OpenAI GPT-4o-mini vs Google Gemini 1.5 Flash 모델 비교`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'query': 'OpenAI GPT-4o-mini vs Google Gemini 1.5 Flash 모델 비교', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://docsbot.ai/models/compare/gpt-4o-mini/gemini-1-5-flash-8b', 'title': 'GPT-4o Mini vs Gemini 1.5 Flash-8B', 'content': \"GPT-4o Mini vs Gemini 1.5 Flash-8B - Detailed Performance & Feature Comparison GPT-4o Mini vs Gemini 1.5 Flash-8B Get a detailed comparison of AI language models OpenAI's GPT-4o Mini and Google's Gemini 1.5 Flash-8B, including model features, token pricing, API costs, performance benchmarks, and real-world capabilities to help you choose the right LLM for your needs. 4.   GPT-4o Mini vs Gemini 1.5 Flash-8B  GPT-4o Mini, developed by OpenAI, features a context window of 128K tokens and can generate up to 16.4K tokens in a single request. Compare costs for input and output tokens between GPT-4o Mini and Gemini 1.5 Flash-8B. Gemini 1.5 Flash-8B is roughly 4.0x cheaper compared to GPT-4o Mini for input and output tokens. *   GPT-4o Mini vs Gemini 1.5 Flash-8B\", 'score': 0.91023487, 'raw_content': None}, {'url': 'https://llm-stats.com/models/compare/gemini-1.5-flash-vs-gpt-4o-mini-2024-07-18', 'title': 'Gemini 1.5 Flash vs GPT-4o mini', 'content': \"Gemini 1.5 Flash accepts 1,048,576 input tokens compared to GPT-4o mini's 128,000 tokens. GPT-4o mini can generate longer responses up to 16,384 tokens, while\", 'score': 0.898277, 'raw_content': None}, {'url': 'https://docsbot.ai/models/compare/gpt-4o-mini/gemini-1-5-flash-002', 'title': 'GPT-4o Mini vs Gemini 1.5 Flash (002)', 'content': 'Gemini 1.5 Flash (002) is 2 months newer than GPT-4o Mini. It has more recent training data (August 2024 vs October 2023). Gemini 1.5 Flash (002) has a larger', 'score': 0.8747745, 'raw_content': None}, {'url': 'https://www.vantage.sh/blog/gpt-4o-small-vs-gemini-1-5-flash-vs-claude-3-haiku-cost', 'title': 'GPT 4-o Mini vs Claude 3 Haiku vs Gemini 1.5 Flash - Vantage', 'content': 'Get started # GPT 4-o Mini vs Claude 3 Haiku vs Gemini 1.5 Flash: Small Language Model Pricing Considerations Gemini 1.5 Flash offers the best balance of affordability and capabilities out of the small language models. OpenAI, Anthropic, and Google have all been competing to ship the most intelligent LLM, as evidenced by their multi-billion parameter, highly performant models (GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, respectively). It is recommended by Amazon for real-time customer support, translations, content moderation, optimized logistics, inventory management, and extraction from unstructured data. Get started with a free trial. Sign up Sign up for free', 'score': 0.85186684, 'raw_content': None}, {'url': 'https://www.vellum.ai/comparison/gpt-4o-mini-vs-gemini-1-5-flash', 'title': 'GPT-4o mini vs Gemini 1.5 Flash', 'content': 'COMPARE LLM MODELS # GPT-4o mini # vs # Gemini 1.5 Flash Compare these models on reasoning, tool use, math, and coding tasks. Check their pricing, speed, and overall performance side by side. Basic Comparison Model Context size Cutoff date Input/Output cost Max output tokens Latency (TTFT) Throughput GPT-4o mini Oct 2023 Gemini 1.5 Flash Standard Benchmarks Dynamic Chart Go to LLM Leaderboard Compare GPT-4o mini with other models Gemini 1.5 Flash vs GPT-4o mini Llama 3.1 70b vs GPT-4o mini Claude 3 Haiku vs GPT-4o mini GPT-4o mini vs GPT-4o GPT-4o mini vs GPT-4', 'score': 0.8338803, 'raw_content': None}], 'response_time': 1.68, 'request_id': '553e13fd-b4bf-4cfc-8095-89eb86603d15'}\u001b[0m\u001b[32;1m\u001b[1;3mOpenAI의 GPT-4o-mini 모델과 구글의 Gemini 1.5 Flash 모델을 비교하면 다음과 같은 주요 차이점이 있습니다:\n",
      "\n",
      "1. **토큰 처리 능력**:\n",
      "   - **GPT-4o-mini**: 최대 128,000개의 입력 토큰을 처리할 수 있으며, 한 번의 요청에서 최대 16,384개의 토큰을 생성할 수 있습니다.\n",
      "   - **Gemini 1.5 Flash**: 최대 1,048,576개의 입력 토큰을 처리할 수 있으며, 이 모델은 더 긴 응답을 생성할 수 있는 능력을 가지고 있습니다.\n",
      "\n",
      "2. **비용**:\n",
      "   - Gemini 1.5 Flash는 입력 및 출력 토큰 비용이 GPT-4o-mini보다 약 4배 저렴합니다. 이는 비용 효율성을 중시하는 사용자에게 중요한 요소가 될 수 있습니다.\n",
      "\n",
      "3. **훈련 데이터**:\n",
      "   - Gemini 1.5 Flash는 2024년 8월까지의 최신 훈련 데이터를 사용하고 있으며, GPT-4o-mini는 2023년 10월까지의 데이터를 기반으로 하고 있습니다. 이는 Gemini 모델이 더 최근의 정보에 기반한 응답을 제공할 수 있음을 의미합니다.\n",
      "\n",
      "4. **성능 및 기능**:\n",
      "   - 두 모델 모두 다양한 작업에서 뛰어난 성능을 보이지만, Gemini 1.5 Flash는 더 많은 입력 토큰을 처리할 수 있어 복잡한 작업이나 대량의 데이터를 다루는 데 유리합니다.\n",
      "\n",
      "5. **응답 속도 및 처리량**:\n",
      "   - 각 모델의 응답 속도와 처리량은 사용 환경에 따라 다를 수 있으며, 특정 작업에 대한 성능은 실제 사용 사례에 따라 달라질 수 있습니다.\n",
      "\n",
      "이러한 차이점들은 사용자의 필요에 따라 적합한 모델을 선택하는 데 중요한 요소가 될 수 있습니다. 더 자세한 비교를 원하시면 [여기](https://docsbot.ai/models/compare/gpt-4o-mini/gemini-1-5-flash-8b)에서 확인할 수 있습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "[최종 답변]: OpenAI의 GPT-4o-mini 모델과 구글의 Gemini 1.5 Flash 모델을 비교하면 다음과 같은 주요 차이점이 있습니다:\n",
      "\n",
      "1. **토큰 처리 능력**:\n",
      "   - **GPT-4o-mini**: 최대 128,000개의 입력 토큰을 처리할 수 있으며, 한 번의 요청에서 최대 16,384개의 토큰을 생성할 수 있습니다.\n",
      "   - **Gemini 1.5 Flash**: 최대 1,048,576개의 입력 토큰을 처리할 수 있으며, 이 모델은 더 긴 응답을 생성할 수 있는 능력을 가지고 있습니다.\n",
      "\n",
      "2. **비용**:\n",
      "   - Gemini 1.5 Flash는 입력 및 출력 토큰 비용이 GPT-4o-mini보다 약 4배 저렴합니다. 이는 비용 효율성을 중시하는 사용자에게 중요한 요소가 될 수 있습니다.\n",
      "\n",
      "3. **훈련 데이터**:\n",
      "   - Gemini 1.5 Flash는 2024년 8월까지의 최신 훈련 데이터를 사용하고 있으며, GPT-4o-mini는 2023년 10월까지의 데이터를 기반으로 하고 있습니다. 이는 Gemini 모델이 더 최근의 정보에 기반한 응답을 제공할 수 있음을 의미합니다.\n",
      "\n",
      "4. **성능 및 기능**:\n",
      "   - 두 모델 모두 다양한 작업에서 뛰어난 성능을 보이지만, Gemini 1.5 Flash는 더 많은 입력 토큰을 처리할 수 있어 복잡한 작업이나 대량의 데이터를 다루는 데 유리합니다.\n",
      "\n",
      "5. **응답 속도 및 처리량**:\n",
      "   - 각 모델의 응답 속도와 처리량은 사용 환경에 따라 다를 수 있으며, 특정 작업에 대한 성능은 실제 사용 사례에 따라 달라질 수 있습니다.\n",
      "\n",
      "이러한 차이점들은 사용자의 필요에 따라 적합한 모델을 선택하는 데 중요한 요소가 될 수 있습니다. 더 자세한 비교를 원하시면 [여기](https://docsbot.ai/models/compare/gpt-4o-mini/gemini-1-5-flash-8b)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Agent 실행 예시 2 ---\")\n",
    "question2 = \"OpenAI의 gpt-4o-mini 모델과 구글의 Gemini 1.5 Flash 모델을 비교 설명해줘.\"\n",
    "response2 = agent_executor.invoke({\"input\": question2})\n",
    "print(\"\\n[최종 답변]:\", response2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zoWUoqzeIBi",
    "outputId": "1df23dcd-2ab6-42a1-c8cc-340b0e39510d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Agent 실행 예시 3 ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Tavily-Search` with `대한민국의 수도`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'query': '대한민국의 수도', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ko.wikipedia.org/wiki/%ED%95%9C%EA%B5%AD%EC%9D%98_%EC%88%98%EB%8F%84', 'title': '한국의 수도', 'content': '| 고구려 기원전 37년~668년 | 수도명 | 현재 위치 | | 수도 기간 |  | | 후백제 892년~936년 | 수도 | 현재 위치 | | 수도 기간 | | 일제강점기 1910년 8월 29일 ~1945년 8월 15일 | 수도 | 현재 위치 | 수도 기간 |  | | 경성부 京城府 | 대한민국 서울특별시 | 1910년 9월 30일~1945년 8월 15일 | | 대한민국 임시정부 1919년~1945년 | 임시 수도 | 현재 위치 | | 임시 수도 기간 |  | | 대한민국 1948년 8월 15일~ | 수도 | 수도 기간 |  | | 서울특별시 | 1953년 7월 27일~현재 | | 조선민주주의인민공화국 1948년 9월 9일~ | 수도명 | 수도 기간 |  | | 평양직할시 平壤直轄市 | 1950년 12월 5일~현재 | ↑ 조선총독부령 제7호 (메이지 43년 10월 1일 공포)', 'score': 0.8684817, 'raw_content': None}, {'url': 'https://m.kin.naver.com/qna/dirs/111001/docs/478501757?d1id=11', 'title': '대한민국 수도 서울 - 네이버 지식iN', 'content': '대한민국 수도 서울 대한민국의 수도인 서울이 어떻게 수도가 됐는지가 궁금합니다. 서울이 조선시대 때 한양이라 불리우며 조선의 수도였던 것은 아는데 그 조선의 수도가 자연스레 한국의 수도가 되어 대한민국의 수도는 서울이다라는 공식 선언같은 건 없이 지금의 대한민국의 수도가 되었다는 말도 있던데 그게 사실인가요?? #문제풀이 우리나라 수도 명칭인 서울은 원래 한 나라의 수도를 뜻하는 순수한 우리말의 일반명사였어요. 그래서 신라의 수도였던 서라벌, 고려의 수도였던 개성도 모두 서울이라고 불렀지요. 조선의 수도였던 한양 역시 사람들은 대부분 지금처럼 서울이라고 불렀어요. 그러다가 서울이 우리나라의 수도이자 지명을 겸하는 제도상 공식명칭으로 쓰이기 시작한 것은   그렇다면 지금의 서울지역은 시대에 따라 어떻게 불렸을까요? 조선시대에는 한양(漢陽) 혹은 한성부(漢城府)로 불렸다는 이야기가 나와요. 우리나라의 수도인 서울 지역의 명칭도 시대에 학점은행제 Expert \"학점은행제 잘 몰랐는데 이해하기 쉽게 설명해 주셔서 감사합니다\" 학점은행제 QnA \"오늘도 문제풀이 감사합니다! 학점은행제 IN Expert', 'score': 0.8619225, 'raw_content': None}, {'url': 'https://namu.wiki/w/%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C', 'title': '서울특별시', 'content': '서울특별시는 대한민국의 수도[22]이자 최대 도시이다. 평양시, 경주시, 개성시, 공주시, 김해시, 부여군, 고령군, 함안군처럼 오랜 역사를 가진 대한민국의 고도 중 하나', 'score': 0.8342047, 'raw_content': None}, {'url': 'https://www.sejong.go.kr/ac/sub02_05.do', 'title': '이 누리집은 대한민국 공식 전자정부 누리집입니다.', 'content': '본문 바로가기 대메뉴 바로가기 **세종 특별자치시** - 대통령 + 대통령 세종집무실 #### 창조와 도전의 미래전략수도 세종 + -개헌 조문에 행정수도를 명시하여, 행정수도를 둘러싼 논란을 종결할 필요 한 나라의 헌법에 수도를 규정하는 것은 각 나라의 역사와 국민 의사를 반영한 선택 + **- 네덜란드 :** 수도는 암스테르담, 행정부를 비롯한 국회·대법원은 헤이그에 위치 + **- 말레이시아 :** 수도 쿠알라룸푸르의 과밀화와 혼잡을 줄이기 위해 푸트라자야를 행정수도로 개발, 2010년까지 정부청사 이전. + **- 남아프리카공화국 :** 행정(프리토리아), 입법(케이프타운), 사법(블룸폰테인) 3개의 수도. **헌법에 행정수도를 조문화하는 방안은?** | 수도·행정수도를 함께 규정 하되, 행정수도에 관한 사항을 법률에 위임 | 대한민국의 수도는 서울특별시로 하고, 행정수도는 세종특별자치시로 한다. 행정 수도에 관한 구체적 사항은 법률로 정한다. | 수도·행정수도를 함께 규정 | 대한민국의 수도는 서울특별시로 하고, 행정수도는 세종특별자치시로 한다. | 행정수도만 규정 | 대한민국의 행정수도는 세종특별자치시로 한다.', 'score': 0.8127637, 'raw_content': None}, {'url': 'https://quizlet.com/kr/591770273/lesson-2-%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98-%EC%88%98%EB%8F%84%EB%8A%94-%EC%84%9C%EC%9A%B8%EC%9E%85%EB%8B%88%EB%8B%A4-flash-cards/', 'title': 'Lesson 2: 대한민국의 수도는 서울입니다 낱말 카드', 'content': 'Lesson 2: 대한민국의 수도는 서울입니다 Flashcards | Quizlet Image 1 Image 2: to visit ### Students also studied Study with Learn Image 29 Image 30: to go up, ascend Image 31: Image: 찾아가다 Image 32: Image: 남산 Image 33: Image: N서울타워 Image 34: Image: 유명하다 Image 35: Image: 올라가다 Image 36: Image: 시내 Image 37: Image: 유람선 Image 38: Image: 도시 Image 39: Image: 현재 Image 40: Image: 과거 N서울타워에 올라가면 서울 시내를 다 볼 수 있고 밤에는 야경을 구경할 수 있습니다. 서울에는 한강도 있습니다. 한강에 가면 유람선을 타고 서울을 구경할 수 있습니다. 그래서 서울에 가면 서울의 현재와 과거를 모두 볼 수 있습니다. Some images used in this set are licensed under the Creative Commons through Flickr.com. *   About Quizlet', 'score': 0.80442166, 'raw_content': None}], 'response_time': 1.13, 'request_id': '21ba28fa-e4df-4e26-bb51-14d493db3c6a'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `write_file` with `{'file_path': 'answer.txt', 'text': '대한민국의 수도는 서울입니다.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mFile written successfully to answer.txt.\u001b[0m\u001b[32;1m\u001b[1;3m파일 'answer.txt'가 성공적으로 생성되었으며, 그 안에 \"대한민국의 수도는 서울입니다.\"라는 내용이 작성되었습니다.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "[최종 답변]: 파일 'answer.txt'가 성공적으로 생성되었으며, 그 안에 \"대한민국의 수도는 서울입니다.\"라는 내용이 작성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Agent 실행 예시 3 ---\")\n",
    "# Wikipedia 도구와 웹 검색 도구를 함께 사용해야 하는 복합적인 질문\n",
    "question3 = \"파일 'answer.txt'를 만들고, 그 안에 대한민국의 수도가 어디인지 검색해서 답을 써줘.\"\n",
    "response3 = agent_executor.invoke({\"input\": question3})\n",
    "print(\"\\n[최종 답변]:\", response3[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9tUouDVbe-kg",
    "4wE6OBqWfPYg",
    "5fXAEeNZgraW",
    "-X--41RUhdeV",
    "cpVwy4F2hsh9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
